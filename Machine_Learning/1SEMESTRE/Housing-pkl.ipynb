{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMY2xj1ndXu6/bjmq1fqS6N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C17o9MCezIey","executionInfo":{"status":"ok","timestamp":1743104719982,"user_tz":180,"elapsed":18501,"user":{"displayName":"Gabriel Dutra","userId":"14961338534389871588"}},"outputId":"94fc916d-e239-43d7-cdf8-06e60e61a065"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['modelo_rf.pkl']"]},"metadata":{},"execution_count":13}],"source":["# Importa as bibliotecas necessárias\n","import pandas as pd  # Para manipulação de dados\n","from sklearn.model_selection import train_test_split  # Para dividir os dados em treino e teste\n","from sklearn.ensemble import RandomForestRegressor  # Para o modelo de regressão RandomForest\n","from sklearn.metrics import mean_squared_error  # Para cálculo do erro quadrático médio\n","from sklearn.impute import SimpleImputer  # Para lidar com valores ausentes nos dados\n","import joblib  # Para salvar o modelo treinado\n","\n","# Carrega o dataset 'housing.csv' em um DataFrame\n","df = pd.read_csv('housing.csv')\n","\n","# Cria variáveis dummy para a coluna 'ocean_proximity', transformando-a em várias colunas binárias\n","df = pd.get_dummies(df, columns=['ocean_proximity'])\n","\n","# Separa as variáveis independentes (X) e a variável dependente (y)\n","x = df.drop('median_house_value', axis=1)  # Exclui a coluna 'median_house_value' de X\n","y = df['median_house_value']  # Define a variável dependente como 'median_house_value'\n","\n","# Divide os dados em conjuntos de treino (80%) e teste (20%) de forma aleatória\n","x_train, x_test, y_train, y_test = train_test_split(\n","    x, y, test_size=0.2, random_state=42  # Usando uma semente fixa para reprodutibilidade\n",")\n","\n","# Cria um objeto SimpleImputer com estratégia de imputação 'median', ou seja, substitui valores ausentes pela mediana\n","imputer = SimpleImputer(strategy='median')\n","\n","# Ajusta e aplica a imputação nos dados de treino\n","x_train = imputer.fit_transform(x_train)\n","\n","# Aplica a imputação nos dados de teste (sem reajustar o modelo)\n","x_test = imputer.transform(x_test)\n","\n","# Cria o modelo de regressão RandomForest\n","modelo_rf = RandomForestRegressor()\n","\n","# Treina o modelo com os dados de treino\n","modelo_rf.fit(x_train, y_train)\n","\n","# Salva o modelo treinado em um arquivo .pkl usando o Joblib\n","joblib.dump(modelo_rf, 'modelo_rf.pkl')"]},{"cell_type":"code","source":["# Importa a biblioteca pandas para manipulação de dados e joblib para carregar o modelo treinado\n","import pandas as pd\n","import joblib\n","\n","# Importa o SimpleImputer da biblioteca sklearn para lidar com valores ausentes\n","from sklearn.impute import SimpleImputer\n","\n","# Carrega um modelo Random Forest previamente treinado de um arquivo .pkl\n","modelo_rf_carregado = joblib.load('modelo_rf.pkl')\n","\n","# Carrega os novos dados de um arquivo CSV, que provavelmente contém dados para previsão\n","novos_dados = pd.read_csv('housing-Copia.csv')\n","\n","# Converte a coluna 'ocean_proximity' em variáveis dummy (variáveis binárias),\n","# ou seja, transforma categorias em colunas de 0 e 1 (one-hot encoding)\n","novos_dados = pd.get_dummies(novos_dados, columns=['ocean_proximity'])\n","\n","# Cria a variável X_novos_dados, que contém todos os dados de entrada (todas as colunas, exceto 'median_house_value')\n","X_novos_dados = novos_dados.drop('median_house_value', axis=1)\n","\n","# Cria uma instância do SimpleImputer, que irá preencher valores ausentes (NaN) com a mediana das colunas\n","imputer = SimpleImputer(strategy='median')\n","\n","# Aplica o SimpleImputer para preencher os valores ausentes em X_novos_dados\n","X_novos_dados_imputados = imputer.fit_transform(X_novos_dados)\n","\n","# Usa o modelo Random Forest carregado para fazer previsões nos dados imputados\n","previsoes = modelo_rf_carregado.predict(X_novos_dados_imputados)\n","\n","# Adiciona a coluna 'previsao_median_house_value' ao dataframe com as previsões feitas\n","novos_dados['previsao_median_house_value'] = previsoes\n","\n","# Salva o dataframe atualizado (com as previsões) em um novo arquivo CSV, sem o índice\n","novos_dados.to_csv('housing-Copia-previsoes.csv', index=False)\n","\n","# Exibe as primeiras 5 linhas do dataframe com as colunas 'median_house_value' e 'previsao_median_house_value' para comparação\n","print(novos_dados[['median_house_value', 'previsao_median_house_value']].head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o1u3tXn0D51A","executionInfo":{"status":"ok","timestamp":1743105417671,"user_tz":180,"elapsed":881,"user":{"displayName":"Gabriel Dutra","userId":"14961338534389871588"}},"outputId":"b7b67a04-5428-4d9e-a8f5-a9687a9255c4"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["   median_house_value  previsao_median_house_value\n","0              452600                    421960.32\n","1              358500                    375595.02\n","2              352100                    377700.04\n","3              341300                    339195.02\n","4              342200                    311495.01\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TWx3LzZnHTsj"},"execution_count":null,"outputs":[]}]}